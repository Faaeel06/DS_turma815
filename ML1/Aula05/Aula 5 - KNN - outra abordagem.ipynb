{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "142facad",
   "metadata": {},
   "source": [
    "# Aula 5 - KNN - outra abordagem"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eb22d22e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-17T22:24:23.353673Z",
     "start_time": "2022-05-17T22:24:23.334000Z"
    }
   },
   "source": [
    "<img src=\"images/knn_intuição.png\"  style=\"width: 700px\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acb7337",
   "metadata": {},
   "source": [
    "### Funcionamento do KNN\n",
    "<img src=\"images/algoritmo_passo_a_passo.png\"  style=\"width: 700px\" />\n",
    "\n",
    "\n",
    "Fonte: https://cambridgecoding.wordpress.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bf9efa",
   "metadata": {},
   "source": [
    "### 2D\n",
    "\n",
    "<img src=\"images/knn_regressão_x_classificação.png\"  style=\"width: 700px\" />\n",
    "\n",
    "<br>\n",
    "\n",
    "Fonte: https://realpython.com/knn-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be666fb",
   "metadata": {},
   "source": [
    "## Medidas de distância\n",
    "\n",
    "<img src=\"images/9_distance_metrics.png\" width=\"600px\" text=\"https://towardsdatascience.com/9-distance-measures-in-data-science-918109d069fa\">\n",
    "\n",
    "### Distância euclidiana\n",
    "$$ D(x,y) = \\sqrt{\\sum_{i=1}^{n}{(x_i - y_i)^2}}$$\n",
    "__Vantagens:__\n",
    "- Muito fácil de entender e aplicar\n",
    "- É a menor distância entre dois pontos em um plano cartesiano\n",
    "- Tem resultados muito bons em dados com baixa dimensionalidade e quando a magnitude do vetor é importante\n",
    "\n",
    "__Desvantagens:__\n",
    "- Não é invariante à escala (as distâncias computadas podem estar skewed dependendo das unidades das features - solução: normalizar os dados)\n",
    "- Quanto maior a dimensionalidade dos seus dados, menos útil é essa distância (devido à Maldição da Dimensionalidade)\n",
    "- Não é recomendada quando o dataset possui atributos discretos e/ou binários\n",
    "\n",
    "### Distância de Manhattan \n",
    "$$ D(x,y) = \\sum_{i=1}^{n}{|x_i - y_i|}$$\n",
    "__Vantagens:__\n",
    "- Utilizada quando podemos apenas se mover em ângulos de 90º como em um tabuleiro de xadrez ou uma cidade. Nesse caso, não há movimentação na diagonal\n",
    "- Não sofre com a maldição da dimensionalidade\n",
    "- Quando o dataset possui atributos discretos e/ou binários\n",
    "\n",
    "__Desvantagens:__\n",
    "- É menos intuitiva, principalmente em grandes dimensões\n",
    "- Fornece distâncias maiores que a Euclidiana (não necessariamente ruim)\n",
    "\n",
    "### Distância de Minkowski\n",
    "$$ D(x,y) = \\begin{pmatrix}\\sum_{i=1}^{n}{|x_i - y_i|^p}\\end{pmatrix}^{1/p}$$\n",
    "\n",
    "- p=1 — Distância de Manhattan\n",
    "- p=2 — Distância euclidiana\n",
    "- p=∞ — Distância de Chebyshev\n",
    "\n",
    "## Maldição da Dimensionalidade\n",
    "<img src=\"images/The-effect-of-the-curse-of-dimensionality-when-projected-in-1-one-dimension-2-two.png\" width=\"600px\" text=\"www.researchgate.net/figure/The-effect-of-the-curse-of-dimensionality-when-projected-in-1-one-dimension-2-two_fig3_342638066\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4dc350",
   "metadata": {},
   "source": [
    "## Normalização / Padronização / Escalas\n",
    "Importante normalizar para que os dados fiquem sempre na mesma escala\n",
    "* Evita que certos algoritmos entendam que determinados atributos tenham mais pesos e sejam considerados mais importantes que outros\n",
    "* Facilita cálculos internos de determinados algoritmos como redes neurais\n",
    "\n",
    "<img src=\"images/normalization.png\"  style=\"width: 400px\" />\n",
    "\n",
    "* Normalização/Standarization\n",
    "\n",
    "1. Min-Max: $$y = (x – min) / (max – min)$$\n",
    "2. Standarization: escalar valores de forma que a média seja igual a zero e o desvio padrão igual a 1, seguindo uma distribuição normal\n",
    "$$y = (x – mean) / standard\\_deviation$$\n",
    "3. RobustScaler: remove outliers seguindo os quartis dos dados e aplica os métodos 1 ou 2 posteriormente <br> <br>\n",
    "\n",
    "OBS 1: $x - mean$ é chamado também de centralização <br>\n",
    "OBS 2: $x/standard\\_deviation$ também é chamado de escala <br>\n",
    "OBS 3: esses métodos devem ser aplicados no dataset de *treinamento* e replicados no teste e validação. Chama-se aplicar a normalização de \"fit\" e replicar seus resultados em outras bases de \"transform\". <br>\n",
    "\n",
    "É considerado **ERRADO** aplicar das formas abaixo: <br>\n",
    "- Normalizar antes de particionar o dataset, aplicando-se a normalização em todos os dados disponíveis <br>\n",
    "- Normalizar treino e teste ao invés de aplicar no teste a normalização realizada no treino <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c2b0c7",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "\n",
    "[Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) é uma classe do sklearn que permite aplicar uma sequência de transformações em um estimador final. <br>\n",
    "Para isso, os passos intermediários devem ter implementados métodos de `fit` e `transform` enquanto o estimador final só precisa ter o `fit` implementado. <br>\n",
    "O propósito do `pipeline` é:\n",
    "- reunir várias etapas para serem validadas de forma cruzada (cross-validation) ao definir parâmetros diferentes\n",
    "- ajudar a criar códigos que possuam um padrão que possa ser facilmente entendido e compartilhando entre times de cientista e engenheiro de dados.\n",
    "\n",
    "<img src=\"images/pipeline.png\" text=\"https://nbviewer.org/github/rasbt/python-machine-learning-book/blob/master/code/ch06/ch06.ipynb#Combining-transformers-and-estimators-in-a-pipeline\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1eec14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
